{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle's Gender Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJGbFQ4qPoW1SGArjfGohY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlotteY2003/MIT-Futuremakers/blob/main/7_21%20-%20Kaggle's_Gender_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gsvl58r7saw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import load_img\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from numpy.random import seed"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MuZJWGR73_B"
      },
      "source": [
        "data = pd.read_csv('age_gender.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGnoONav-AKA"
      },
      "source": [
        "#Convert each item of pixels into array\n",
        "def string_to_arr(X, width, height):\n",
        "  X = X.reset_index(drop=True)\n",
        "  X = X.apply(lambda x: np.array(x.split(), dtype='float32'))\n",
        "  #X = np.array(X)/255.0\n",
        "  #Why can't we add normalization here?\n",
        "  X = np.array([X[i].reshape(width, height, 1) for i in range(X.shape[0])])\n",
        "  return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YABGzaEMxWlW"
      },
      "source": [
        "def data_preprocess(data):\n",
        "  data = data[data['age'] >= 18]\n",
        "  data.reset_index(drop=True, inplace=True)\n",
        "  data = data.dropna()\n",
        "\n",
        "  num_pixels = len(data['pixels'][0].split())\n",
        "  dimensions = int(np.sqrt(num_pixels))\n",
        "  width = dimensions\n",
        "  height = dimensions\n",
        "  print(num_pixels, width, height)\n",
        "\n",
        "  X_img = data.pixels #same as data.iloc[:,4]\n",
        "  y_gender = data.gender\n",
        "  y_ethnicity = data.ethnicity\n",
        "  y_age = data.age\n",
        "\n",
        "  X_train, X_te, y_train, y_te = train_test_split(X_img, y_gender, test_size = .3, random_state = 11)\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_te, y_te, test_size = .15, random_state=11)\n",
        "\n",
        "  X_train = string_to_arr(X_train, width, height)\n",
        "  X_test = string_to_arr(X_test, width, height)\n",
        "  X_val = string_to_arr(X_val, width, height)\n",
        "\n",
        "  #Why can't we convert entire X instead of splitting it, then converting multiple parts of X?\n",
        "  print(X_train.shape)\n",
        "\n",
        "  target_columns = ['age', 'ethnicity', 'gender']\n",
        "  \n",
        "  data.drop(labels='img_name', axis=1)\n",
        "  \n",
        "  y = data[target_columns]\n",
        "  X = data.drop(labels=target_columns, axis=1)\n",
        "  #X (pd dataframe) = has column name while X_img (pd series) does not during initalization\n",
        "\n",
        "  X = X['pixels'].apply(lambda x: np.array(x.split(), dtype='float32'))\n",
        "  X = np.array(X)/255.0 #Why don't we add normalization to X_test, X_train, X_val\n",
        "  X = np.array([ X[i].reshape(48,48,1) for i in range(X.shape[0]) ])\n",
        "\n",
        "  y_gender = np.array(y['gender']) # To reduce num lines used, couldn't we just do y_gender = np.array(data.gender) instead of making variable y\n",
        "  y_ethnicity = np.array(y['ethnicity'])\n",
        "  y_age = np.array(y['age'])\n",
        "\n",
        "  return X,y_gender, X_train, X_test, X_val, y_train, y_test, y_val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTMbczhA6ibM"
      },
      "source": [
        "def data_aug(X_val, y_val, X_test, y_test):\n",
        "  train_data_gen = ImageDataGenerator(rotation_range=30,\n",
        "                                      width_shift_range = 1,\n",
        "                                      brightness_range=[.8,1.2],\n",
        "                                      zoom_range = [.8,1.2],\n",
        "                                      rescale=1/255)\n",
        "  val_data_gen = ImageDataGenerator(rescale=1/255)\n",
        "  test_data_gen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "  np.random.seed(11)\n",
        "\n",
        "  val_data = val_data_gen.flow(X_val, y_val, shuffle = False, seed= 11)\n",
        "  test_data = test_data_gen.flow(X_test, y_test, shuffle=False, seed=11)\n",
        "  \n",
        "  return val_data, test_data, train_data_gen"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2cOVHeZLLEP"
      },
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform', input_shape = (48,48,1,)))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Dropout(.3))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Dropout(.3))\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Dropout(.5))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(128, activation='softmax', kernel_initializer='he_uniform')) #Why is ouput units not 1 or 2?\n",
        "\n",
        "  #optimizer = SGD(learning_rate=.01, momentum=.9)\n",
        "  model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy']) #Why do we need sparse categorical instead of binary?\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWBN13sXMb6Y"
      },
      "source": [
        "def train_test(X, y_gender, train_data_gen, nsplit=10):\n",
        "  \n",
        "  loss_per_fold = list()\n",
        "  histories = list()\n",
        "  scores = list()\n",
        "  kf = KFold(n_splits = nsplit, shuffle=True)\n",
        "\n",
        "  es = EarlyStopping(min_delta=.01, monitor='val_loss', patience=5, mode='min') #restore_best_weights=True)\n",
        "  #checkpoint = ModelCheckpoint('weights.h5', mode = 'min', save_best_only=True)\n",
        "  \n",
        "  for traini, testi in kf.split(X,y_gender):\n",
        "    model = build_model()\n",
        "    np.random.seed(11)\n",
        "    \n",
        "    train_data = train_data_gen.flow(X[traini], y_gender[traini], seed=11)\n",
        "    temp_val_data = train_data_gen.flow(X[testi], y_gender[testi], seed=11)\n",
        "    history = model.fit(train_data, epochs = 50, batch_size = 32, validation_data = temp_val_data, \n",
        "                        verbose = 1, callbacks=es) #steps_per_epoch = 10,\n",
        "  \n",
        "    score = model.evaluate(temp_val_data, verbose=0)\n",
        "    scores.append(score[1])\n",
        "    loss_per_fold.append(scores[0])\n",
        "    histories.append(history)\n",
        "\n",
        "  #model.load_weights('weights.h5')\n",
        "  \n",
        "  return scores, histories, loss_per_fold"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb4s57RTgkPA"
      },
      "source": [
        "def evaluate_performance(scores, histories, loss_per_fold):\n",
        "  for i in range(len(histories)):\n",
        "    plt.plot(histories[i].history['loss'], label='train', color='blue')\n",
        "    plt.plot(histories[i].history['val_loss'], label='test', color='orange')\n",
        "    plt.title('Model ' + str(i+1) + \" loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(histories[i].history['accuracy'], label = 'train', color='blue')\n",
        "    plt.plot(histories[i].history['val_accuracy'], label = 'test', color='orange')\n",
        "    plt.title('Model ' + str(i+1) + \" accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  plt.plot(scores)\n",
        "  plt.title('Overall scores')\n",
        "  plt.show()\n",
        "\n",
        "  print('----------------------------------------------')\n",
        "  print('Mean scores: ' + str(np.mean(scores)))\n",
        "  print('Standard deviation of scores: ' + str(np.std(scores)))\n",
        "  print('----------------------------------------------')\n",
        "  print('Mean loss: ' + str(np.mean(loss_per_fold)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2nfH7ofhdfd"
      },
      "source": [
        "def run_test(data):\n",
        "  X,y_gender, X_train, X_test, X_val, y_train, y_test, y_val = data_preprocess(data)\n",
        "  #What is the use of X_train or y_test\n",
        "  \n",
        "  \n",
        "  val_data, test_data, train_data_gen = data_aug(X_val, y_val, X_test, y_test)\n",
        "  \n",
        "  scores, histories, loss_per_fold = train_test(X, y_gender, train_data_gen) #Why not use X_train and y_train here?\n",
        "  evaluate_performance(scores, histories)\n",
        "  \n",
        "  final_train = np.append(X_train, X_val, axis=0)\n",
        "  final_val = np.append(y_train, y_val, axis=0) #Shouldn't it be x,y? Variable names are confusing\n",
        "  final_training_data = train_data_gen.flow(final_train, final_val, seed=11) #What's the point of this if we're not going to use it?\n",
        "\n",
        "  np.random.seed(11)\n",
        "  model = build_model()\n",
        "  \n",
        "  np.random.seed(11)\n",
        "  history = model.fit(train_data_gen.flow(X,y_gender, seed=11), epochs = 20, batch_size = 32, validation_data = val_data, \n",
        "                        verbose = 1) #steps_per_epoch = 10\n",
        "                        #confused on this line - final_training_data is never used \n",
        "                        \n",
        "  model.evaluate(test_data)\n",
        "\n",
        "  y_pred = model.predict_classes(test_data)\n",
        "\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  \n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  sns.heatmap(cm, cmap = 'Greens', cbar=False, annot=True, fmt='d')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOma5OYLmrDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d301e76-d284-491a-b858-219db4f12ac7"
      },
      "source": [
        "run_test(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2304 48 48\n",
            "(13630, 48, 48, 1)\n",
            "Epoch 1/50\n",
            "548/548 [==============================] - 525s 919ms/step - loss: 0.9565 - accuracy: 0.6793 - val_loss: 0.3480 - val_accuracy: 0.8506\n",
            "Epoch 2/50\n",
            "548/548 [==============================] - 496s 905ms/step - loss: 0.3381 - accuracy: 0.8576 - val_loss: 0.2793 - val_accuracy: 0.8763\n",
            "Epoch 3/50\n",
            "548/548 [==============================] - 491s 897ms/step - loss: 0.2761 - accuracy: 0.8855 - val_loss: 0.2695 - val_accuracy: 0.8871\n",
            "Epoch 4/50\n",
            "548/548 [==============================] - 495s 904ms/step - loss: 0.2619 - accuracy: 0.8982 - val_loss: 0.2362 - val_accuracy: 0.9189\n",
            "Epoch 5/50\n",
            "548/548 [==============================] - 502s 915ms/step - loss: 0.2445 - accuracy: 0.9016 - val_loss: 0.2089 - val_accuracy: 0.9148\n",
            "Epoch 6/50\n",
            "548/548 [==============================] - 496s 904ms/step - loss: 0.2232 - accuracy: 0.9151 - val_loss: 0.2099 - val_accuracy: 0.9209\n",
            "Epoch 7/50\n",
            "548/548 [==============================] - 495s 903ms/step - loss: 0.2164 - accuracy: 0.9197 - val_loss: 0.2171 - val_accuracy: 0.9132\n",
            "Epoch 8/50\n",
            "548/548 [==============================] - 493s 900ms/step - loss: 0.2179 - accuracy: 0.9173 - val_loss: 0.2134 - val_accuracy: 0.9220\n",
            "Epoch 9/50\n",
            "548/548 [==============================] - 493s 899ms/step - loss: 0.2009 - accuracy: 0.9267 - val_loss: 0.2010 - val_accuracy: 0.9292\n",
            "Epoch 10/50\n",
            "548/548 [==============================] - 496s 905ms/step - loss: 0.1944 - accuracy: 0.9275 - val_loss: 0.1875 - val_accuracy: 0.9322\n",
            "Epoch 11/50\n",
            "548/548 [==============================] - 505s 921ms/step - loss: 0.1869 - accuracy: 0.9291 - val_loss: 0.1884 - val_accuracy: 0.9343\n",
            "Epoch 12/50\n",
            "548/548 [==============================] - 498s 910ms/step - loss: 0.1798 - accuracy: 0.9339 - val_loss: 0.1736 - val_accuracy: 0.9389\n",
            "Epoch 13/50\n",
            "548/548 [==============================] - 504s 919ms/step - loss: 0.1823 - accuracy: 0.9325 - val_loss: 0.1718 - val_accuracy: 0.9358\n",
            "Epoch 14/50\n",
            "548/548 [==============================] - 500s 912ms/step - loss: 0.1726 - accuracy: 0.9376 - val_loss: 0.2012 - val_accuracy: 0.9215\n",
            "Epoch 15/50\n",
            "548/548 [==============================] - 499s 911ms/step - loss: 0.1632 - accuracy: 0.9410 - val_loss: 0.1802 - val_accuracy: 0.9328\n",
            "Epoch 16/50\n",
            "548/548 [==============================] - 499s 911ms/step - loss: 0.1668 - accuracy: 0.9369 - val_loss: 0.1898 - val_accuracy: 0.9333\n",
            "Epoch 17/50\n",
            "548/548 [==============================] - 495s 904ms/step - loss: 0.1647 - accuracy: 0.9398 - val_loss: 0.1616 - val_accuracy: 0.9456\n",
            "Epoch 18/50\n",
            "548/548 [==============================] - 493s 899ms/step - loss: 0.1615 - accuracy: 0.9408 - val_loss: 0.1754 - val_accuracy: 0.9353\n",
            "Epoch 19/50\n",
            "548/548 [==============================] - 496s 905ms/step - loss: 0.1523 - accuracy: 0.9448 - val_loss: 0.1931 - val_accuracy: 0.9286\n",
            "Epoch 20/50\n",
            "548/548 [==============================] - 498s 909ms/step - loss: 0.1530 - accuracy: 0.9449 - val_loss: 0.1541 - val_accuracy: 0.9430\n",
            "Epoch 21/50\n",
            "548/548 [==============================] - 497s 907ms/step - loss: 0.1431 - accuracy: 0.9512 - val_loss: 0.1679 - val_accuracy: 0.9435\n",
            "Epoch 22/50\n",
            "548/548 [==============================] - 491s 896ms/step - loss: 0.1410 - accuracy: 0.9507 - val_loss: 0.1675 - val_accuracy: 0.9348\n",
            "Epoch 1/50\n",
            "548/548 [==============================] - 490s 890ms/step - loss: 0.9709 - accuracy: 0.6691 - val_loss: 0.3854 - val_accuracy: 0.8321\n",
            "Epoch 2/50\n",
            "548/548 [==============================] - 489s 892ms/step - loss: 0.3410 - accuracy: 0.8599 - val_loss: 0.3243 - val_accuracy: 0.8737\n",
            "Epoch 3/50\n",
            "548/548 [==============================] - 490s 895ms/step - loss: 0.2877 - accuracy: 0.8838 - val_loss: 0.2907 - val_accuracy: 0.8783\n",
            "Epoch 4/50\n",
            "246/548 [============>.................] - ETA: 4:27 - loss: 0.2731 - accuracy: 0.8864"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvGFJsuRpYRN"
      },
      "source": [
        "import cv2\n",
        "img = cv2.imread('../input/testset/mind-long.jpg',0)\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "img = cv2.resize(img, (48,48))\n",
        "img = np.reshape(img,[1,48,48,1])\n",
        "img_pixels = img.astype(\"float32\") / 255.0\n",
        "classes = model.predict_classes(img_pixels)\n",
        "\n",
        "mapper=['male','female']\n",
        "print(mapper[classes[0]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}