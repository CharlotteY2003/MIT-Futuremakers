{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Affective Computing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNC+IRzxGiDAMzD1WrCUxB8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlotteY2003/MIT-Futuremakers/blob/main/7_28-Affective_Computing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqNwhHJugs3A",
        "outputId": "73352b38-75aa-4404-c9a2-d95c7eb0fd94"
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.5).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.7/dist-packages (0.2.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPLOq2LegxpY",
        "outputId": "c2ece63b-ca19-4c93-b6f9-faf6e1dd5df3"
      },
      "source": [
        "!pip install wave"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wave in /usr/local/lib/python3.7/dist-packages (0.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMwYz8q7gnwd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pyaudio\n",
        "import wave\n",
        "from keras.models import model_from_json\n",
        "from keras.optimizers import RMSprop\n",
        "import librosa\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "vTj2vhwRg0mN",
        "outputId": "3b23e961-f027-4f8d-f86e-60adde9a8071"
      },
      "source": [
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 2\n",
        "RATE = 44100\n",
        "RECORD_SECONDS = 4\n",
        "WAVE_OUTPUT_FILENAME = 'output10.wav'\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT,channels=CHANNELS,\n",
        "                rate=RATE,input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "print('recording')\n",
        "\n",
        "frames=[]\n",
        "\n",
        "for i in range(0,int(RATE/CHUNK * RECORD_SECONDS)):\n",
        "  data = stream.read(CHUNK)\n",
        "  frames.append(data) #2 bytes (16 bits) per channel\n",
        "\n",
        "print('done recording')\n",
        "\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n",
        "\n",
        "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
        "wf.setnchannels(CHANNELS)\n",
        "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "wf.setframerate(RATE)\n",
        "wf.writeframes(b''.join(frames))\n",
        "wf.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4dc44f63eb2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m stream = p.open(format=FORMAT,channels=CHANNELS,\n\u001b[1;32m     11\u001b[0m                 \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 frames_per_buffer=CHUNK)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recording'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_streams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# calling pa.open returns a stream object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_latency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputLatency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno -9996] Invalid input device (no default output device)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLqo60Adivx5"
      },
      "source": [
        "json_file = open('model.json'. 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights('Emotion_Voice_Detection_Model.h5')\n",
        "opt = RMSprop(lr=.00001,decay=1e-6)\n",
        "loaded_model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpvGIKppomuH"
      },
      "source": [
        "data, sampling_rate = librosa.load('output10.wav')\n",
        "plt.figure(figsize=(15,5))\n",
        "librosa.display.waveplot(data,sr=sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D7WC0F6zEGH"
      },
      "source": [
        "X, sample_rate = librosa.load('output10.wav',res_type='kaiser_fast',duration=2.5,sr=22050*2, offset=.5)\n",
        "sample_rate = np.array(sample_rate)\n",
        "mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=13), axis=0)\n",
        "featurelive = mfccs\n",
        "livedf2 = featurelive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aXDbbjpBqKw"
      },
      "source": [
        "livedf2 = pd.Dataframe(data=livedf2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azi_oLLpButX"
      },
      "source": [
        "livedf2 = livedf2.stack().to_frame().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R9q6mkyB0xQ"
      },
      "source": [
        "livedf2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjuqU-B2B94a"
      },
      "source": [
        "twodim = np.expand_dims(livedf2,axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRU75MELCIOC"
      },
      "source": [
        "livepreds = loaded_model.predict(twodim,\n",
        "                                 batch_size=32,\n",
        "                                 verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r7BiYkVi-Jc"
      },
      "source": [
        "livepreds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ2VYPnTCQXt"
      },
      "source": [
        "livepreds1 = livepreds.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIlLKp4FCWIs"
      },
      "source": [
        "livepredsabc = livepreds.astype(int).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bWssDJZCcwg"
      },
      "source": [
        "livepredictions = (lb.inverse_transform((live_abc)))\n",
        "livepredictions"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}